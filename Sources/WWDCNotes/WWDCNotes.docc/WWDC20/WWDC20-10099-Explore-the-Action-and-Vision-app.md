# Explore the Action & Vision app

It's now easy to create an app for fitness or sports coaching that takes advantage of machine learning&nbsp;‚Äî&nbsp;and to prove it, we built our own. Learn how we designed the Action & Vision app using Object Detection and Action Classification in Create ML along with the new Body Pose Estimation, Trajectory Detection, and Contour Detection features in the Vision framework. Explore how you can create an immersive application for gameplay or training from setup to analysis and feedback. And follow along in Xcode with a full sample project.

To get the most out of this session, you should have familiarity with the Vision framework and Create ML‚Äôs Action Classifier tools. To learn more, we recommend watching ‚ÄúBuild an Action Classifier with Create ML,‚Äù ‚ÄúExplore Computer Vision APIs,‚Äù and ‚ÄúDetect Body and Hand Pose with Vision.‚Äù We also recommend exploring the Action & Vision sample project to learn more about adopting these technologies.

Whether you are building a fitness coaching app, or exploring new ways of interacting, consider the incredible features that you can build by combining machine learning with the rich set of computer vision features. By bringing Create ML, Core ML, and Vision API together, there's almost no end to the magic you can bring to your app.

@Metadata {
   @TitleHeading("WWDC20")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/wwdc20/10099", purpose: link, label: "Watch Video (36 min)")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

üò± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn More‚Ä¶](https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing)
