# Deploy machine learning and AI models on-device with Core ML

Learn new ways to optimize speed and memory performance when you convert and run machine learning and AI models through Core ML. Weâ€™ll cover new options for model representations, performance insights, execution, and model stitching which can be used together to create compelling and private on-device experiences.

@Metadata {
   @TitleHeading("WWDC24")
   @PageKind(sampleCode)
   @CallToAction(url: "https://developer.apple.com/wwdc24/10161", purpose: link, label: "Watch Video")

   @Contributors {
      @GitHubUser(<replace this with your GitHub handle>)
   }
}

ðŸ˜± "No Overview Available!"

Be the hero to change that by watching the video and providing notes! It's super easy:
 [Learn Moreâ€¦](https://wwdcnotes.github.io/WWDCNotes/documentation/wwdcnotes/contributing)
